{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ae83a28-5221-46f4-a8bc-cd4bd3ff7b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeout\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e10c853-6e07-4ebb-9540-dbc25f53aa21",
   "metadata": {},
   "source": [
    "playwright is used to go to a specific page, get the html tag, and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cdf6b56-4149-4a0b-8aaf-1e3bb723aee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEASONS = list(range(2016,2023))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cd8b06f-4173-4a61-8fe1-67b25ecdfb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2016, 2017, 2018, 2019, 2020, 2021, 2022]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEASONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ca70615-8a96-4041-88ea-48461dec8dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR=\"data\"\n",
    "STANDINGS_DIR=os.path.join(DATA_DIR, \"standings\")\n",
    "SCORES_DIR = os.path.join(DATA_DIR, \"scores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8325fe-c1bd-4af6-8e04-043ab5c63fd3",
   "metadata": {},
   "source": [
    "We need to setup an async function because we want to run it in another thread, \n",
    "It will run in another stack "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ee88f07-6991-4a48-b508-f62d6bd0dd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_html(url, selector, sleep=5, retries=3):\n",
    "    html=None\n",
    "    #Running this for the tries we have retries\n",
    "    for i in range(1, retries+1):\n",
    "        #Have a sleep variable because sometimes scraping to fast is not good and gets us banned\n",
    "        time.sleep(sleep*i)\n",
    "\n",
    "        #Need a try and catch bloch  incase webscrapping fails\n",
    "        try:\n",
    "            async with async_playwright() as p:\n",
    "                #opens a new chrome browser and starts a new page\n",
    "                browser = await p.chromium.launch(headless=True)\n",
    "                page = await browser.new_page()\n",
    "                await page.goto(url)\n",
    "                print(await page.title())\n",
    "                html = await page.inner_html(selector)\n",
    "        #If we cannot scrape the html we get a playwright timeout error\n",
    "        except PlaywrightTimeout:\n",
    "            print(f\"cannot scrape for url {url} in the {i+1} try\")\n",
    "            #This makes it so the we start again with the loop for the number of retries\n",
    "            continue\n",
    "        #If we dont get an error we skip the except block meaning we got a successful scrape, so we break in the else block\n",
    "        else:\n",
    "            break\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8128fb59-dc8c-416f-bb5c-e584a197f88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot scrape for url https://www.basketball-reference.com/leagues/NBA_2016_games.html in the 2 try\n",
      "2015-16 NBA Schedule | Basketball-Reference.com\n",
      "cannot scrape for url https://www.basketball-reference.com/leagues/NBA_2016_games.html in the 3 try\n",
      "2015-16 NBA Schedule | Basketball-Reference.com\n",
      "cannot scrape for url https://www.basketball-reference.com/leagues/NBA_2016_games.html in the 4 try\n"
     ]
    }
   ],
   "source": [
    "# Now we scrape to get the single season page\n",
    "season  = 2016\n",
    "url = f\"https://www.basketball-reference.com/leagues/NBA_{season}_games.html\"\n",
    "#Since css classes arnt uniqie and id's are, we first choose a unique id then a filter, which has all the href tags\n",
    "html = await get_html(url, \"#content.filter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a173158-e8d1-49a4-ab92-4b85b769e7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c99550e-0ffe-4a6b-ace3-de806f697158",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
